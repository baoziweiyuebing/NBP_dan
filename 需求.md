 

 

**需求整理 11-17_update****：**

 

**一、背景需求说明：**

基于仓库NextBestPath, 将仿真效果迁移到实体机器人go2w上。论文里面的核心思想：用最短路径来探索最多的区域（自主探索）。

 

**二、****需求：**

**在对于原始代码改动最小的情况下，实现功能：将仿真相机输入替换成realsense d435i****输入，同时将仿真中相机的位姿更新动作同步到现实中机器狗的运动中，实现现实机器狗的运动与仿真中相机运动规划保持一致，驱动机器狗在室内环境里面自主探索。**

 

**产出：有完整的测试代码，参考仿真中的test_nbp_planning.py****，需要为实机测试写一个测试代码，运行结束后，（1****）能够展现出机器狗探索的全部历史轨迹点位；（2****）能够保存出当前未知环境（例如：一个房间等）的完整点云信息，可以将保存的ply****文件用openply.py** **文件查看。**

 

**1.** **需求：真实传感器数据接入- realsense d435i**

原始代码仓中，利用仿真中的相机作为传感器入口，我们需要将仿真相机替换为realsense d435i，

**参考：**可以参考real_camera_impl.py 文件的实机接口，关注macarons_utils.py 文件里面的capture_image() 函数，参考该原始函数，返回值的images，depth信息可以从realsense d435i相机获取，

关于R-旋转，T-平移 的位姿矩阵，可以从轮足机器狗宇树go2w中获取，可以参考 real_world_env.py 文件，包含RT姿态获取等功能函数（宇树的go2w sdk 测试已跑通）；

 

以下为相机中的capture_image() 函数的更改，在此处保留了仿真中的fov_camera.R, foc_camera.T 两处，但是要不要用实体的机器狗的参数，需要你判断一下；

 

![940230fe66ab3b9df947d752696a5fba](file:///C:/Users/12423/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg)

 

 

**2.** **功能需求：在探索过程中累计点云，**

 

原始代码仓中，存在点云计算功能，即累计已探索空间的点云信息，并且将每一步骤的点云保存成partial.ply文件，将总体累计点云保存成 full_pc.ply 文件。

 

问题：在实机部署中，我们需要保存的点云具有空间感，才能保证后续的机器人点位规划与轨迹规划的正确性；

 

仿真中就有很好的空间感：

如下使我们运行的仿真效果：

![82d124825afbfa2f224b75bbe9c9bfb2](file:///C:/Users/12423/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg)

 

 

 

 

 

**3.** **功能需求：轨迹规划及存储，**

 

原始代码的功能还有一点可以将下一个step的轨迹规划出来；并将历史轨迹存储下来；

 

我们的需求：

（1）按照算法规划的点位，将机器狗从一个位置驱动到另一个位置，**这部分需要把机器狗的运动功能集成进去**，机器狗的sdk我们有提供，可以参考外部单个文件——Unigoal_Action_Mapping.py，只需要给机器狗的（vx,vy,vyaw）指令即可调用底层sdk逻辑；

 

我们在整体代码仓中更改的Unigoal_Action_Mapping.py文件，需要重写控制机器狗移动逻辑的 move_to_pose() 函数，此处目前有问题。

 

（2）可视化轨迹点位——用rviz 功能；（最好能有一个可视化的验证工具）

将机器狗走的轨迹点位在rviz中或其他可视化软件中呈现出来；

 